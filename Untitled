模块,核心知识点 (The What),复习执行动作 (The How),面试应对场景 (The Why)
分布式并行(Megatron-LM),Tensor Parallel (TP),画图： 默写 MLP 和 Attention 层的切分方式（Row vs Col）。标出 f (Copy) 和 g (AllReduce) 算子的位置。,“请在白板上画一下 Megatron 是怎么切分 Transformer 的？”
流水线并行(Pipeline),1F1B 调度 & 气泡 (Bubble),"算数： 搞懂 1F1B（1 Forward 1 Backward）的流水线图。背诵气泡率公式：(P−1)/M (P=阶段数, M=Micro-batch)。",“流水线并行的效率瓶颈在哪里？如何减少气泡？”
显存优化(DeepSpeed),ZeRO-1/2/3 体系,画图： 画出显存分布金字塔（参数、梯度、优化器状态各占多少）。理解： ZeRO-Offload 是怎么利用 CPU 内存和 NVMe 的。,“训练千亿模型显存不够怎么办？ZeRO-3 会增加通信量吗？”
通信原语(NCCL),集合通信 (Collectives),"看图： 搞懂 All-Reduce, All-Gather, Reduce-Scatter 的区别。知道 Ring 和 Tree 算法的基本概念。",“DDP 用的是哪种通信原语？TP 用的是哪种？”
性能分析(Profiling),Nsight Systems (nsys),看图： 找几张 Timeline 截图，学会一眼识别：哪里是 Compute (计算)，哪里是 Communication (通信)，哪里是 Idle (空闲)。,“你是怎么定位训练瓶颈的？（答案：看 Overlap 情况）”