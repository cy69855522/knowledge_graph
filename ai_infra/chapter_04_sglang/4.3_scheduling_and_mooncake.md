# 4.3 Mooncake & Disaggregated Scheduling: 存储为中心的分离式架构 🍰

## 🎯 核心目标
如果我的显卡资源是弹性的，或者分布在不同的机房，vLLM 还能高效工作吗？
Mooncake 提出了 **KVCache-centric (以 KV Cache 为中心)** 的调度思想，彻底解耦了 Prefill 和 Decode。

## 💡 概念解析

### 1. 传统 vLLM 的局限: "卡与卡绑定" 🔗
在 vLLM 中，显卡被牢牢地捆绑在一起 (TP/PP)。
*   如果你要扩容，你得加一组卡。
*   如果 Prefill 负载 heavy，Decode 负载 light，你的资源就可能闲置。

### 2. Mooncake 的解法: "KV Cache 才是一切" 🔑
Mooncake 认为，显卡只是算力 worker，**KV Cache 才是核心资产**。
*   **Prefill Worker (P):** 计算 Prompt 的 KV Cache，然后丢进一个共享的存储池 (Shared KVCache Pool)。
*   **Decode Worker (D):** 只要能读到 KV Cache，谁来接着生成都可以！
*   **Decoupled Scheduling:** 调度器直接在全局层面管理 KV Cache 的流动。

#### 📸 CV 工程师类比
*   **Centralized Warehouse vs Distributed Shops:**
    *   **vLLM:** 就像每个前置仓 (Shop) 都有自己的库存。如果这个仓缺货了，哪怕隔壁仓爆仓，也不能互相借调 (或者很难借)。
    *   **Mooncake:** 就像 **京东/亚马逊大仓 (Centralized Warehouse)**。
        *   所有的货 (KV Cache) 入库后，统一管理。
        *   任何一个配送员 (Decode Worker) 都可以来领任务。
        *   这种架构特别适合 **Servingless** 场景，资源随用随取，弹性伸缩极快。

### 3. Chunked Prefill (分块预填充) 🧱
由于 Mooncake 是以块为单位管理 KV Cache 的，它还可以做 **Chunked Prefill**。
*   如果 Prompt 超长 (1M tokens)，单个 Prefill Worker 算不过来。
*   Mooncake 可以把 Prompt 切成几段，分发给多个 Worker 同时算 KV Cache，最后再拼起来。**就像 MapReduce 一样并行化 Prefill！**

## ⚔️ 课后实战 (Action Items)
1.  **Architecture:** 画一下 Mooncake 的 KV Transfer 路径。
    *   (提示: RDMA 是关键。如果网络慢，传输 KV Cache 的时间会抵消并行的收益)。
2.  **Trade-off:** 这种分离式架构有什么缺点？
    *   (提示: 网络带宽成了新的瓶颈。Local Hit (本地命中) 永远比 Remote Access (远程访问) 快。Mooncake 的调度器必须极力优化 Data Locality，尽量让 Decode 发生在刚刚算完 Prefill 的机器附近)。
