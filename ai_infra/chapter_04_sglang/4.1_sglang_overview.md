# 4.1 SGLang: 给大模型装上"编程语言"的翅膀 🧚‍♂️

## 🎯 核心目标
vLLM 跑得很快，但如果你在做 **Agent** (智能体)，你会发现 vLLM 很难用。
SGLang (Structured Generation Language) 的出现，就是为了解决 **复杂控制流 (Complex Control Flow)** 和 **结构化输出 (Structured Output)** 的效率问题。

## 💡 概念解析

### 1. vLLM 的痛点: "Python 胶水" 🧩
传统的 Agent 开发模式 (如 LangChain) 是：
1.  Python 拼一个 Prompt -> 发给 vLLM -> 等待 HTTP 返回。
2.  解析返回的 String -> Python 写个 `if-else` -> 拼下一个 Prompt。
3.  发给 vLLM -> 等待...

**问题:**
*   **网络开销:** 每一轮交互都要走一次 HTTP/gRPC，像挤牙膏一样。
*   **Prompt 重复:** 每一轮都要把历史对话发过去，vLLM 虽然有 Prefix Caching，但调度器层面的开销依然存在。

### 2. SGLang 的解法: "Runtime 里的解释器" ⚡️
SGLang 允许你用一种**类似于 Python 的 DSL (领域特定语言)** 来描述整个交互流程，然后**一次性**发给推理引擎执行。

*   **Compiler Optimization:** SGLang 后端会分析你的各种 `fork` (并行生成)、`join` (汇聚)、`select` (选择) 操作，自动合并请求，最大化 GPU 利用率。
*   **RadixAttention:** 利用前缀树 (Radix Tree) 极其激进地复用 KV Cache (下一节细讲)。

#### 📸 CV 工程师类比
*   **OpenGL / CUDA Graph:**
    *   **vLLM (Eager Mode):** 就像你用 PyTorch 逐行执行 `a+b`, `c*d`。每一行都要启动一个 Kernel，CPU 和 GPU 频繁交互。
    *   **SGLang (Graph Mode):** 就像 **CUDA Graph**。你定义好整个计算图 (Workflow)，然后把整个图丢给 GPU。GPU 自己在该跳转的时候跳转，没有 Python 解释器的 overhead。

### 3. Structured Generation (结构化生成) 🏗️
Agent 经常需要输出 JSON 格式。
*   **Naive:** 提示词写 "Please output JSON"。模型经常只输出一半，或者忘了那个 `}`。
*   **SGLang:** 利用 **Finite State Machine (FSM)** 在解码端强行约束 Token 的采样。
    *   如果到了该输出 `key` 的时候，只允许模型从字符串词表中采样。
    *   如果到了该输出 `value` 的时候，如果是数字，就禁止采样字母。
    *   **结果:** 100% 符合 JSON Schema，且因为搜索空间变小了，推理速度反而**更快**！

## ⚔️ 课后实战 (Action Items)
1.  **Try it:** 用 SGLang 写一个 "Few-shot Prompting" 的 Pipeline。
    *   你会发现它能自动复用 few-shot examples 的 KV Cache，比手动拼接快得多。
2.  **Benchmark:** 对比一下生成 JSON 的速度。
    *   Plain Prompt vs SGLang Regex Constraint。后者通常更快，因为不用生成废话。
