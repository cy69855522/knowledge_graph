# 5.1 Chip Architecture: 深入显卡的心脏 🫀

## 🎯 核心目标
为什么写 kernel 很难？因为你必须手动管理数据的搬运。
了解 GPU 的 **Memory Hierarchy (存储层级)** 和 **Compute Units (计算单元)** 是写出高性能算子的前提。

## 💡 概念解析

### 1. SM (Streaming Multiprocessor): 显卡的各个车间 🏭
GPU 并不是一个巨大的单一核心，而是由几十上百个 **SM (流式多处理器)** 组成的。
*   **A100:** 拥有 108 个 SM。每个 SM 都是一个独立的指挥部。
*   **内部构造:** 每个 SM 内部包含了：
    *   **CUDA Cores:** 负责通用计算 (FP32, INT32)。
    *   **Tensor Cores:** 负责矩阵运算。
    *   **LD/ST Units:** 负责读写显存。
    *   **SFU:** 算 sin/cos/exp。
    *   **Register File & Shared Memory:** 极速存储。
    *   **Warp Scheduler:** 线程调度器。

#### 📸 CV 工程师类比
*   **The Factory:**
    *   **GPU:** 整个富士康工厂。
    *   **SM:** 工厂里的 **108 个独立车间**。
    *   **Threads:** 车间里的几千名工人。
    *   **关键点:** 任务会被分配给这 108 个车间并行处理。一旦分配进去，车间之间偶尔通过电话 (L2 Cache / HBM) 沟通，但主要还是闷头干活。

### 2. Memory Hierarchy: 距离产生美 (也产生延迟) 📏
我们在 3.5 节已经见过这张图，现在让我们更深入一点。

*   **HBM (Global Memory):** 显存。容量大 (80GB)，但离计算核心远，带宽虽高 (2TB/s) 但延迟也高。
    *   *CV 类比:* **仓库**。存着几万吨原材料。
*   **L2 Cache:** 所有 SM 共享的缓存 (40MB+)。
    *   *CV 类比:* **车间门口的中转站**。
*   **SRAM (Shared Memory / L1):** 每个 SM 私有的高速缓存 (192KB)。**这是 Kernel 优化的主战场**。
    *   *CV 类比:* **流水线旁边的料框**。伸手就能拿，速度极快。
*   **Registers (寄存器):** 就在计算单元手边。
    *   *CV 类比:* **工人的手**。

### 3. Tensor Cores: 专为矩阵乘法生的怪兽 🦖
以前的 GPU (Pascal 架构之前) 只有 CUDA Cores (FP32)。
Volta 架构引入了 **Tensor Cores**，专门用来做 $D = A \times B + C$ 这种矩阵乘法 (GEMM)。
*   **FP32 Core:** 一次算一个数的乘加。
*   **Tensor Core:** 一次算一个 $4 \times 4$ 或 $16 \times 8 \times 8$ 的小矩阵乘法。
*   **算力差距:** Tensor Core 的吞吐量是 CUDA Core 的 **8-16 倍**！这也解释了为什么我们要用 FP16/BF16 (Tensor Core 的原生精度)。

#### 📸 CV 工程师类比
*   **Image Filtration:**
    *   **CUDA Core:** 就像你写一个双重 for 循环，手动通过 `result += pixel * weight` 来算卷积。通用，但慢。
    *   **Tensor Core:** 就像你调用了 `cv2.filter2D`，或者是硬件级别的 ISP 模块。它内部有专门的电路直接并行把一小块像素和卷积核“压”在一起算出结果。

### 4. NVLink: 卡与卡的高速公路 🛣️
在单机多卡 (8x A100) 训练或推理时，必须要频繁交换数据 (All-Reduce)。
*   **PCIe:** 慢，只有 32GB/s。
*   **NVLink:** 快，双向带宽 600GB/s。
*   **NVSwitch:** 类似于交换机，让 8 张卡两两互联 (Fully Connected)。

## ⚔️ 课后实战 (Action Items)
1.  **Check Hardware:** 运行 `nvidia-smi topo -m`。
    *   看看你的卡之间是 `NV` (NVLink) 还是 `PIX` (PCIe)？这决定了你能否高效跑张量并行 (TP)。
2.  **Coding:** 写一个简单的 PyTorch 矩阵乘法，分别用 `float32` 和 `float16` 跑。
    *   观察时间差。你会发现 `float16` 快很多，就是因为用上了 Tensor Cores。
