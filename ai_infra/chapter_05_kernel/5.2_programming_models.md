# 5.2 Programming Models: SIMD vs SIMT 👯‍♂️

## 🎯 核心目标
为什么 CPU 跑得快是单核强，GPU 跑得快是核多？
理解 **SIMD** (CPU 的并行模式) 和 **SIMT** (GPU 的并行模式) 是写好 Kernel 的关键。

## 💡 概念解析

### 1. SIMD (Single Instruction, Multiple Data) 🚄
这是 CPU 常用的并行方式 (AVX, NEON)。
*   **指令:** 一条指令 (如 `_mm_add_ps`) 可以同时操作 4 个或 8 个 float。
*   **执行:** 一个核内，ALU 同时干活。
*   **CV 类比:** 就像你的一只手有 5 根手指，你可以指挥这 5 根手指同时按钢琴键。

### 2. SIMT (Single Instruction, Multiple Threads) 💃
这是 GPU (CUDA) 的并行方式。
*   **指令:** 也是一条指令。
*   **执行:** 但不是操作 8 个 float，而是同时启动了 **32 个线程 (Threads)**。这一组线程叫做 **Warp (线程束)**。
*   **Lockstep (同步):** 这 32 个线程必须步伐一致。如果有人执行 `if`，有人执行 `else` (Branch Divergence)，整个 Wap 就必须串行执行这两个分支，效率减半。

#### 📸 CV 工程师类比
*   **Array Manipulation:**
    *   **SIMD:** 就像你想把图片每一个像素加 1。你用这只 5 根手指的手，一次抓 5 个像素加 1。
    *   **SIMT:** 就像你有 **1000 个分身**。
        *   大家听到大喇叭喊 "Add 1!"。
        *   每个分身拿出自己负责的那 1 个像素，同时加 1。
        *   **关键:** 大喇叭只能喊同一个指令。

### 3. Grid, Block, Thread 🏢
CUDA 的层级结构：
*   **Grid:** 整个计算任务。
*   **Block:** 能够在一个 SM 上协同工作的一组线程 (比如 128 个)。Block 内部可以通过 SRAM (Shared Memory) 交换数据。
*   **Thread:** 最小的执行单元。拥有自己的寄存器。

## ⚔️ 课后实战 (Action Items)
1.  **Thinking:** 为什么在 CUDA 里尽量避免 `if-else` 分支？
    *   (提示: Warp Divergence。因为 32 个线程必须共进退。如果一半走 if 一半走 else，实际上全员都要等两边都跑完)。
2.  **Coding:** 写一个简单的 CUDA Kernel (比如 Vector Add)，分别设 Block Size = 32, 128, 1024。看看对性能有什么影响。
    *   (提示: Occupancy。Block 太小或太大都会导致 SM 跑不满)。
