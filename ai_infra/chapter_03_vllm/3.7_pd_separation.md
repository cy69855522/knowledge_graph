# 3.7 PD Separation (Prefill-Decode Separation) 🚧

## 🎯 核心目标
如何让 **Prefill** (计算密集型) 和 **Decode** (访存密集型) 两个性格迥异的兄弟不打架？

## 💡 概念解析

### 1. Head-of-Line Blocking (队头阻塞) 🛑
*   **问题:** 如果一个 GPU 同时接了两个请求：
    *   请求 A: 刚刚来，还没Prefill，Prompt 50000 tokens。这需要耗时 2秒算第一步。
    *   请求 B: 已经生成了一半，只剩下一个小 Decode 步。
*   **后果:** 为了处理请求 A 的 Prefill，请求 B 必须**被迫等待 2秒**。
*   **用户体验:** 用户 B 觉得卡住了 (Stuttering)。这叫 **Head-of-Line Blocking**。

#### 📸 CV 工程师类比
*   **Mixed Frame Processing:**
    *   处理视频流时，如果突然来了一帧极其复杂的 8K 全景 I-frame (Key Frame)，解码器卡住了。
    *   后面的 P-frame 虽然只要算一点点残差，但也得乖乖排队等着。导致画面突然卡顿一下。

### 2. PD Separation (PD 分离) ✂️
为了解决上述问题，我们将 GPU 分成两组：
*   **Prefill Workers (Group A):** 专门负责处理新来的 Prompt，干重活累活 (Compute Bound)。
*   **Decode Workers (Group B):** 专门负责生成 Token，干轻巧活 (Memory Bound)。

### 3. Workflow 🛠️
1.  用户请求 -> Router。
2.  Router 发给 Prefill Worker。
3.  Prefill Worker 算出 KV Cache。
4.  **KV Cache Transfer:** 把算好的 KV Cache 通过高速网络传给 Decode Worker。
5.  Decode Worker 接手，开始生成 Token。

**优势:** 生成任务永远不会被新来的 Prompt 打断，TPOT (Time Per Output Token) 极其稳定！平滑如丝 🕊️。

## ⚔️ 课后实战 (Action Items)
1.  **Architecture Design:** 如果让你设计这一套系统，你会用什么协议传 KV Cache？
    *   (提示: TCP? No。RDMA (RoCE) 是必须的。带宽至少要 200Gbps+ 才能跟上生成速度)。
2.  **Resource Allocation:** 你会给 Prefill 分更多卡，还是给 Decode 分更多卡？
    *   (提示: 取决于你的业务场景是长 Prompt (RAG) 多，还是长 Output (写小说) 多)。
