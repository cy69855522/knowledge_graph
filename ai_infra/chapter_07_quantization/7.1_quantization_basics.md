# 7.1 Quantization Basics: 这里的公式其实很简单 🧮

## 🎯 核心目标
为什么模型能量化？因为神经网络对噪声是很鲁棒的。
本节核心是搞懂 **INT8 量化公式**：如何把一个浮点数映射到整数，再映射回来。

## 💡 概念解析

### 1. The Magic Formula (量化公式) ✨
量化的本质就是 **线性映射 (Affine Mapping)**。
我们要把浮点数 $R$ (Real value, e.g., -5.2 ~ 10.5) 映射到整数 $Q$ (Quantized value, e.g., -128 ~ 127)。

$$ R = S \times (Q - Z) $$
$$ Q = \text{round}(\frac{R}{S} + Z) $$

其中：
*   **$R$ (Real):** 原始的 FP32/FP16 数值。
*   **$Q$ (Quantized):** 量化后的 INT8 数值。
*   **$S$ (Scale):** 缩放因子 (步长)。类似地图的比例尺。
*   **$Z$ (Zero-point):** 零点偏移。浮点数的 0 对应整数的多少。

#### 📸 CV 工程师类比
*   **Levels Adjustment (色阶调整):**
    *   你有一张 HDR 图片 (FP32)，像素值范围是 -5.2 到 10.5 (假设没做归一化)。
    *   你要把它存成 JPG (INT8, 0-255)。
    *   **Scale ($S$):** $\frac{R_{max} - R_{min}}{Q_{max} - Q_{min}} = \frac{10.5 - (-5.2)}{255 - 0} \approx 0.061$. (每个整数代表 0.061 的亮度变化)。
    *   **Zero-point ($Z$):** $R=0$ 的时候，$Q$ 应该是多少？要把 $R_{min}$ 也就是 -5.2 映射到 0，$0$ 大概映射到 $85$。所以 $Z=85$。

### 2. Symmetric vs Asymmetric (对称 vs 非对称) ⚖️
*   **Symmetric (对称量化):**
    *   强制 $Z = 0$。
    *   映射范围是对称的 (e.g., -127 ~ 127)。
    *   **优点:** 计算简单 (少一步减法)，推理快。**Wights (权重)** 通常分布比较对称，适合用这个。
    *   **公式:** $Q = \text{round}(R / S)$。

*   **Asymmetric (非对称量化):**
    *   $Z \neq 0$。
    *   映射范围不对称 (e.g., RELU 后的激活值是 0 ~ 100)。
    *   **优点:** 精度高，不浪费 bit。**Activations (激活值)** 通常用这个 (因为 ReLU 之后全是正数)。

### 3. Granularity (量化粒度) 🔬
*   **Per-Tensor:** 整个 Layer 的权重共享同一个 $S$ 和 $Z$。
    *   *CV 类比:* 整张图用一套色阶参数。如果图里既有极黑又有极亮的区域，细节就丢了。
*   **Per-Channel (常用):** 每一行或每一列权重独享一套 $S$ 和 $Z$。
    *   *CV 类比:* 局部自适应直方图均衡化 (CLAHE)。每一块区域单独修图，细节保留最好。

## ⚔️ 课后实战 (Action Items)
1.  **Calculate:**
    *   给定 $R_{min}=-10, R_{max}=30$。
    *   目标 INT8 (0~255)。
    *   求 $S$ 和 $Z$。
    *   $S = (30 - (-10)) / 255 = 40 / 255 \approx 0.157$.
    *   $Z = \text{round}(0 - (-10) / 0.157) = 64$.
    *   验证: $Q = 10 \rightarrow R = 0.157 * (10 - 64)$ ❌... 等等，zero point 是 $R=0$ 映射到的整数值。 $Z = - R_{min} / S = 10 / 0.157 \approx 63.7 \rightarrow 64$。
    *   所以 $R=0$ 时 $Q=64$。
    *   $R=30$ 时 $Q = 30/0.157 + 64 \approx 191 + 64 = 255$. ✅
