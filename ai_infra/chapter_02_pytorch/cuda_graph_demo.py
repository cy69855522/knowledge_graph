import torch
import time

def verify_cuda_graph():
    if not torch.cuda.is_available():
        print("Skipping CUDA Graph verification (CUDA not available)")
        return

    print("Verifying CUDA Graph implementation...")
    
    # 1. å‡†å¤‡æ•°æ® (Static Input)
    N, D_in, D_out = 64, 1024, 1024
    # å¿…é¡»æ˜¯ CUDA tensor
    x = torch.randn(N, D_in, device='cuda')
    y = torch.randn(N, D_out, device='cuda')
    model = torch.nn.Linear(D_in, D_out).cuda()
    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)

    # 2. Warmup (çƒ­èº«) - æå…¶é‡è¦ï¼è®© Pytorch åˆ†é…æ˜¾å­˜
    # åŒæ—¶ä¹Ÿä½œä¸ºä¸€ä¸ª side_streamï¼Œé¿å…å¹²æ‰°é»˜è®¤æµ
    s = torch.cuda.Stream()
    s.wait_stream(torch.cuda.current_stream())
    with torch.cuda.stream(s):
        for _ in range(3):
            optimizer.zero_grad(set_to_none=True)
            y_pred = model(x)
            loss = (y_pred - y).pow(2).sum()
            loss.backward()
            optimizer.step()
    torch.cuda.current_stream().wait_stream(s)

    # 3. Capture (å½•åˆ¶) ğŸ¥
    g = torch.cuda.CUDAGraph()
    optimizer.zero_grad(set_to_none=True) # Important: call outside capture

    # Capture context
    with torch.cuda.graph(g):
        y_pred = model(x)
        loss = (y_pred - y).pow(2).sum()
        loss.backward()
        optimizer.step()

    # 4. Replay (å›æ”¾) ğŸ¬
    print("Graph captured! Replaying...")
    start = time.time()
    # å‡å°‘è¿­ä»£æ¬¡æ•°ï¼Œé¿å…è·‘å¤ªä¹…
    for _ in range(10):
        g.replay()
    torch.cuda.synchronize() # ç­‰å¾… GPU è·‘å®Œ
    print(f"10 iter finished in {time.time() - start:.4f}s")
    print("Verification SUCCESS! ğŸ‰")

if __name__ == "__main__":
    try:
        verify_cuda_graph()
    except Exception as e:
        print(f"Verification FAILED: {e}")
        exit(1)
