# 6.2 AI Compilers: 从图优化到代码生成 🧬

## 🎯 核心目标
现代 AI 编译器到底在做什么？
它的核心工作流是：Frontend (Python) -> Graph Optimization (IR) -> Backend (Code Generation)。

## 💡 概念解析

### 1. Frontend & Graph IR (前端与图中间表示) 🖼️
*   **Frontend:** 接收 PyTorch/TensorFlow 的模型定义。
*   **Graph IR:** 将模型转换成一个计算图 (Computational Graph)。
*   **Optimization:** 在图层级做 High-Level 优化。
    *   **Operator Fusion (算子融合):** 把 `Conv + BatchNorm + ReLU` 融合成一个大 Kernel。
    *   **Constant Folding (常量折叠):** 编译期算出固定参数。
    *   **Dead Code Elimination (死代码消除):** 删掉没有用到的分支。

#### 📸 CV 工程师类比
*   **Photoshop Action:**
    *   **Naive:** 打开图 -> 滤镜A -> 保存 -> 打开 -> 滤镜B -> 保存。
    *   **Fusion:** 这一连串滤镜都在显存里做完，最后只存一次图。

### 2. Backend & Kernel Tuning (后端与算子调优) 🔧
*   **Backend:** 把优化后的图，针对特定硬件生成代码 (LLVM IR -> ASM)。
*   **Tuning:** 这一步最难。
    *   **Loop Tiling:** 怎么切分循环能最大化 Cache 命中率？
    *   **Vectorization:** 怎么用上 SIMD/Tensor Cores？
    *   **Auto-Tuning:** 像 TVM (Ansor) 这种编译器，会自动搜索几千种可能的代码实现，选出最快的那一个。

### 3. Case Study: Torch.compile (Inductor) 🔥
PyTorch 2.0 引入了 `torch.compile`。
*   **Dynamo:** 捕获 Python 的动态图。
*   **AOT Autograd:** 提前算出反向传播图。
*   **Inductor:** 使用 Triton 生成高性能的融合算子。
*   **Result:** 一行代码提速 30%~200%。

## ⚔️ 课后实战 (Action Items)
1.  **Usage:** 在你的 PyTorch 代码里加一行 `model = torch.compile(model)`。
    *   看看第一次运行是不是变慢了？(Compile Time Overhead)。
    *   看看后续运行是不是变快了？(Runtime Speedup)。
2.  **Inspect:** 设置 `TORCH_LOGS="output_code"` 环境变量。
    *   看看 Inductor 到底给你生成了什么样的 Triton 代码。你会发现它把很多小的 element-wise ops 都融合成了一个大 Kernel。
