# 1.3 延迟 (Latency) vs 吞吐 (Throughput) ⏱️🌊

## 🎯 核心目标
鱼和熊掌不可兼得 🐻🐾。在 Infra 中，你是要是 **快 (Low Latency)** 还是要 **多 (High Throughput)**？

## 💡 概念解析

### 1. Latency (延迟) - Time To First Token (TTFT) ⏱️
*   **定义:** 从用户发出请求，到看到**第一个字**吐出来的时间。
*   **关键指标:** `TTFT (Time To First Token)`.
*   **谁关心:** 用户 (User Experience)。太慢了用户会以为网页卡死了。
*   **受什么影响:** Prefill 阶段的计算量 (Prompt 越长，Prefill 越慢)。

#### 📸 CV 工程师类比
*   **Live Object Detection (实时检测):** 无人驾驶汽车 🚗。必须要 < 30ms 看到结果。
    *   **追求:** Batch Size = 1。哪怕显卡算力没吃满，为了快也只能设为 1。

### 2. Throughput (吞吐) - Tokens Per Second (TPS) 🌊
*   **定义:** 系统每秒钟能生成多少个 Token (所有用户的总和)。
*   **关键指标:** `Generation Throughput`.
*   **谁关心:** 老板 (Cost Efficiency)。吞吐越高，每张卡能服务的用户越多，成本越低 💰。
*   **受什么影响:** Batch Size (Batch 越大，并行度越高，虽然单次推理变慢了，但总产出变多了)。

#### 📸 CV 工程师类比
*   **Offline Video Processing (离线视频处理):** 给几万个视频打标签 🏷️。
    *   **追求:** Batch Size = 256 (或者显存撑爆为止)。不在乎单张图是不是处理了 500ms，只在乎一天能处理成千上万张图。

### 3. The Trade-off (权衡) ⚖️
在显存允许的情况下：
*   **增大 Batch Size:**
    *   ✅ Throughput 变大 (GPU 利用率高)。
    *   ❌ Latency 变大 (单个请求排队久，计算久)。
*   **减小 Batch Size:**
    *   ✅ Latency 变小 (响应快)。
    *   ❌ Throughput 变小 (显卡空转，老板亏钱)。

**AI Infra 工程师的工作:** 在满足 SLA (例如 TTFT < 200ms) 的前提下，**玩命提高 Throughput**。

## ⚔️ 课后实战 (Action Items)
1.  **思考:** 为什么 vLLM 的 PagedAttention 和 Continuous Batching 能同时改善 Latency 和 Throughput？(提示：主要是为了 Throughput，但通过减少排队间接改善了长尾延迟)。
2.  **算账:** 假设 1 张 A100 租金 $3/hr。
    *   方案 A: Batch=1, Latency=50ms, Throughput=20 TPS。
    *   方案 B: Batch=16, Latency=200ms, Throughput=100 TPS。
    *   如果用户能接受 200ms 延迟，你会选哪个方案？显然是 B，成本只有 A 的 1/5 📉。
