# 第六章：性能考虑 ⭐

## 6.1 内存合并 (Memory Coalescing) ⭐

### DRAM 工作原理
- DRAM 访问延迟：**数十纳秒**（vs 亚纳秒时钟周期）
- **突发传输 (Burst)**：每次访问返回一段连续数据
- 利用突发 → 高带宽；随机访问 → 低带宽

### 合并访问
当 **Warp 内线程访问连续内存地址** 时，硬件将多个访问**合并为一个 DRAM 请求**。

```cpp
// ✅ 合并访问：连续线程访问连续地址
M[Row * Width + k]  // k 相同，Row 连续 → 访问同一行连续元素

// ❌ 非合并访问：连续线程访问跨行地址
M[k * Width + Col]  // Col 连续，但访问不同行 → 地址间隔 Width
```

### 行主序 vs 列主序

**行主序 (Row-Major)**：同一行元素连续存储
```
M[0][0], M[0][1], M[0][2], M[0][3], M[1][0], M[1][1], ...
```

**合并规则**：
- 访问**同一行**的连续元素 → ✅ 合并
- 访问**同一列**的连续元素 → ❌ 非合并（跨行）

### Corner Turning 优化
当必须访问列优先数据时，用共享内存中转：

```cpp
// 1. 以合并方式加载到共享内存（交换 tx/ty）
Nds[tx][ty] = N[(ph * TILE_WIDTH + tx) * Width + col];
__syncthreads();

// 2. 在共享内存中执行非合并访问（共享内存不需要合并）
Pvalue += Mds[ty][k] * Nds[k][tx];
```

## 6.2 隐藏内存延迟

### DRAM 并行结构
```
处理器 ← 多个通道 (Channel) ← 每个通道多个存储体 (Bank)
```

- **通道 (Channel)**：独立的内存控制器 + 总线
- **存储体 (Bank)**：独立的 DRAM 阵列

### 延迟隐藏原理
```
Bank 0: 访问延迟 ████████ 传输 ██
Bank 1:          访问延迟 ████████ 传输 ██
Bank 2:                   访问延迟 ████████ 传输 ██
```

当一个 Bank 等待访问时，其他 Bank 可以传输数据。

### 所需 Bank 数量
$$
\text{Bank 数量} \geq \frac{\text{访问延迟}}{\text{传输时间}} + 1
$$

### 与占用率的关系
- **高占用率** → 更多并行内存请求 → 更好利用 Bank 并行性
- 最大化占用率同时隐藏：
  1. 核心流水线延迟
  2. DRAM 访问延迟

## 6.3 线程粗化 (Thread Coarsening)

### 问题：并行化的代价
- 不同块重复加载相同数据
- 冗余工作
- 同步开销

### 解决方案
每个线程处理**多个工作单元**，减少并行化开销。

### 矩阵乘法示例
```cpp
#define COARSE_FACTOR 2

// 每个线程负责 COARSE_FACTOR 个输出元素
float Pvalue[COARSE_FACTOR] = {0};

for (int ph = 0; ph < numTiles; ph++) {
    // 加载一个 M tile（只加载一次）
    Mds[ty][tx] = M[...];
    
    // 加载多个 N tile 并计算
    for (int c = 0; c < COARSE_FACTOR; c++) {
        int col = colStart + c * TILE_WIDTH;
        Nds[ty][tx] = N[...];
        __syncthreads();
        
        for (int k = 0; k < TILE_WIDTH; k++) {
            Pvalue[c] += Mds[ty][k] * Nds[k][tx];
        }
        __syncthreads();
    }
}

// 写回多个输出
for (int c = 0; c < COARSE_FACTOR; c++) {
    P[Row * Width + colStart + c * TILE_WIDTH] = Pvalue[c];
}
```

### 注意事项
1. **不要过度粗化**：保留足够并行度
2. **注意资源消耗**：粗化可能增加寄存器/共享内存使用
3. **不是所有计算都需要**：无并行化代价时（如向量加法）无需粗化

## 6.4 优化检查表 ⭐

| 优化 | 计算收益 | 内存收益 | 策略 |
|------|----------|----------|------|
| **最大化占用率** | 隐藏流水线延迟 | 隐藏 DRAM 延迟 | 调整块大小、寄存器、共享内存使用 |
| **内存合并** | 减少等待 | 提高带宽利用 | Corner turning、重排数据布局 |
| **减少分支** | 提高 SIMD 效率 | - | 重排线程-数据映射 |
| **Tiling** | 减少等待 | 减少全局访问 | 共享内存/寄存器缓存复用数据 |
| **私有化** | 减少原子操作等待 | 减少竞争 | 本地累加后合并 |
| **线程粗化** | 减少冗余工作 | 减少冗余加载 | 每线程多工作单元 |

## 6.5 识别性能瓶颈

### 常见瓶颈
1. **内存带宽受限**：算术强度低
2. **计算受限**：算术强度高
3. **占用率受限**：资源使用过多
4. **分支受限**：Warp 内分歧严重

### 分析工具
- **Nsight Compute (ncu)**：详细的 Kernel 性能分析
- **Nsight Systems (nsys)**：系统级性能分析

### 优化原则
> 优化要**针对瓶颈**！
> - 瓶颈是内存 → Tiling、合并
> - 瓶颈是计算 → 算法优化
> - 瓶颈是占用率 → 减少资源使用

## 6.6 核心总结

### SGEMM 优化路线
```
1. Naive Kernel
   ↓ 问题：内存带宽受限 (0.25 FLOP/B)
2. Shared Memory Tiling
   ↓ 问题：可能有非合并访问
3. Memory Coalescing (Corner Turning)
   ↓ 问题：仍有冗余加载
4. Thread Coarsening
   ↓ 问题：寄存器压力
5. Register Tiling + 向量化加载
   → 接近峰值性能
```

### 关键公式

**合并效率**：
$$
\text{效率} = \frac{\text{实际传输字节}}{\text{请求传输字节}}
$$

**内存带宽利用率**：
$$
\text{利用率} = \frac{\text{实际带宽}}{\text{峰值带宽}}
$$

### 黄金法则
1. **先分析，后优化**：用 profiler 找瓶颈
2. **优化瓶颈资源**：不要盲目优化
3. **权衡取舍**：一种优化可能增加另一种资源压力
4. **测试验证**：优化效果因设备/数据而异
