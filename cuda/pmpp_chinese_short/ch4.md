# 第四章：计算架构和调度 ⭐

## 4.1 GPU 架构概览

### SM (Streaming Multiprocessor)
- GPU 由多个 **SM** 组成
- 每个 SM 包含多个 **CUDA Core**
- 例：Ampere A100 = 108 SM × 64 Core = 6912 Core

### 内存层级
- **片上内存 (On-chip)**：寄存器、共享内存、L1 Cache
- **片外内存 (Off-chip)**：全局内存 (HBM/DRAM)

## 4.2 块调度

### 调度规则
1. **同一块的所有线程分配到同一个 SM**
2. 一个 SM 可同时分配多个块
3. 块执行完毕后，新块被调度到空闲 SM

```
Grid → 多个 Block → 分配到 SM → 执行
```

### 透明可扩展性
- 块之间**无同步依赖**，可以任意顺序执行
- 低端 GPU：串行执行少量块
- 高端 GPU：并行执行大量块
- **相同代码，不同硬件，自动适配**

## 4.3 同步

### `__syncthreads()`
- **块内**线程的屏障同步
- 所有线程到达同步点后才继续执行

```cpp
__shared__ float data[256];
data[threadIdx.x] = input[i];
__syncthreads();  // 等待所有线程完成写入
// 现在可以安全读取其他线程写入的数据
```

### 注意事项
- ⚠️ 所有线程必须执行相同的 `__syncthreads()`
- ⚠️ 不要在条件分支中使用（可能导致死锁）

```cpp
// ❌ 错误：可能死锁
if (threadIdx.x % 2 == 0) {
    __syncthreads();
} else {
    __syncthreads();  // 这是不同的同步点！
}
```

## 4.4 Warp 和 SIMD 硬件 ⭐

### Warp 概念
- **Warp = 32 个连续线程**（硬件调度单位）
- 块被划分为多个 Warp

```
Block (256 threads) → 8 Warps (32 threads each)
Warp 0: thread 0-31
Warp 1: thread 32-63
...
```

### 多维块的线程化
```cpp
// 2D Block 8x8 → 64 threads → 2 Warps
// 线性化顺序：先 x，再 y
// Warp 0: (y=0,x=0-7), (y=1,x=0-7), (y=2,x=0-7), (y=3,x=0-7)
// Warp 1: (y=4,x=0-7), (y=5,x=0-7), (y=6,x=0-7), (y=7,x=0-7)
```

### SIMD 执行模型
- **同一 Warp 的所有线程执行相同指令**
- 每个线程操作不同数据
- 共享控制逻辑，节省芯片面积

## 4.5 控制分支 (Control Divergence) ⭐

### 什么是分支？
当 Warp 内线程走不同执行路径时发生分支。

```cpp
if (threadIdx.x < 16) {
    A();  // Pass 1: 线程 0-15 执行
} else {
    B();  // Pass 2: 线程 16-31 执行
}
C();      // 所有线程重新汇聚
```

### 性能影响
- **分支 Warp 需要多次执行**（每条路径一次）
- 非活动线程浪费执行资源
- **避免在 Warp 内分支！**

### 边界条件分支
```cpp
// 这种分支通常只影响最后一个 Warp
if (i < n) {
    // 处理数据
}
```

**影响分析**：
- 向量长度 100：4 个 Warp 中 1 个分支 → 25% 影响
- 向量长度 1000：32 个 Warp 中 1 个分支 → 3% 影响
- 向量长度 10000：313 个 Warp 中 1 个分支 → <1% 影响

## 4.6 Warp 调度和延迟隐藏 ⭐

### 延迟隐藏原理
当一个 Warp 等待长延迟操作（如内存访问）时，**切换到另一个就绪的 Warp 执行**。

```
Warp 0: 执行 → 等待内存 → (休眠)
Warp 1:                    → 执行 → 等待内存 → (休眠)
Warp 2:                                        → 执行 → ...
```

### 零开销调度
- 所有 Warp 的状态保存在**硬件寄存器**中
- 切换 Warp **不需要保存/恢复状态**
- 无上下文切换开销

### 关键点
- SM 分配的线程数 >> 同时执行的线程数
- 例：A100 SM 可分配 2048 线程，但只有 64 Core
- **过量分配是延迟隐藏的关键**

## 4.7 资源划分和占用率 (Occupancy) ⭐

### 占用率定义
$$
\text{Occupancy} = \frac{\text{分配的 Warp 数}}{\text{SM 支持的最大 Warp 数}}
$$

### SM 资源限制（以 A100 为例）
| 资源 | 限制 |
|------|------|
| 最大线程数 | 2048 |
| 最大块数 | 32 |
| 最大寄存器数 | 65536 |
| 每块最大线程数 | 1024 |

### 占用率受限场景

**场景 1：块太小**
```
块大小 = 32 线程
SM 最多 32 块 → 只能分配 1024 线程
占用率 = 1024/2048 = 50%
```

**场景 2：块大小不整除**
```
块大小 = 768 线程
SM 只能容纳 2 块 → 1536 线程
占用率 = 1536/2048 = 75%
```

**场景 3：寄存器不足**
```
每线程 64 寄存器
最多支持 65536/64 = 1024 线程
占用率 = 1024/2048 = 50%
```

### 性能悬崖
寄存器使用量的微小增加可能导致占用率骤降！

```
31 寄存器/线程 → 2048 线程 → 100% 占用率
33 寄存器/线程 → 1536 线程 → 75% 占用率  ⚠️
```

## 4.8 查询设备属性

```cpp
int devCount;
cudaGetDeviceCount(&devCount);

cudaDeviceProp prop;
cudaGetDeviceProperties(&prop, 0);

// 常用属性
prop.multiProcessorCount    // SM 数量
prop.maxThreadsPerBlock     // 每块最大线程数
prop.regsPerBlock           // 每 SM 寄存器数
prop.warpSize               // Warp 大小 (通常 32)
prop.maxThreadsDim[3]       // 块各维度最大线程数
prop.maxGridSize[3]         // 网格各维度最大块数
```

## 4.9 核心总结

| 概念 | 要点 |
|------|------|
| **SM** | GPU 基本执行单元，包含多个 Core |
| **Warp** | 32 线程，SIMD 执行，调度单位 |
| **控制分支** | 同 Warp 不同路径 → 多次执行 → 性能下降 |
| **延迟隐藏** | Warp 切换隐藏内存延迟，零开销 |
| **占用率** | 实际线程/最大线程，受块大小、寄存器等限制 |
| **透明可扩展** | 块无依赖，自动适配不同硬件 |

### SGEMM 优化启示
1. **块大小选择**：32 的倍数，平衡占用率
2. **避免 Warp 分支**：数据访问模式统一
3. **最大化占用率**：控制寄存器使用
4. **利用延迟隐藏**：足够的并行度
