# 第十六章：深度学习

## 核心概念

### 16.1 感知器 (Perceptron)

线性分类器：$y = \text{sign}(w_1 x_1 + w_2 x_2 + b)$

- **推理**：计算输出类别
- **训练**：调整权重使误差最小

### 16.2 多层感知器 (MLP)

多层组合实现复杂分类边界：
```
输入 → 隐藏层1 → 隐藏层2 → ... → 输出
```

### 16.3 训练过程

#### 前向传播
计算每层输出，直到最终预测

#### 反向传播
从输出层向输入层传播梯度：
$$\frac{\partial E}{\partial w} = \frac{\partial E}{\partial y} \cdot \frac{\partial y}{\partial w}$$

#### 权重更新
$$w \leftarrow w - \epsilon \frac{\partial E}{\partial w}$$

其中 $\epsilon$ 是学习率

### 16.4 卷积神经网络 (CNN)

#### 卷积层
```cpp
// 前向传播
for (int m = 0; m < M; m++)           // 输出特征图
for (int h = 0; h < H_out; h++)       // 高度
for (int w = 0; w < W_out; w++) {     // 宽度
    float sum = 0;
    for (int c = 0; c < C; c++)       // 输入通道
    for (int p = 0; p < K; p++)       // 滤波器高度
    for (int q = 0; q < K; q++) {     // 滤波器宽度
        sum += X[c][h+p][w+q] * W[m][c][p][q];
    }
    Y[m][h][w] = sum;
}
```

#### 池化层
下采样，减少特征图尺寸：
```cpp
Y[m][h][w] = average(X[m][h*2:h*2+2][w*2:w*2+2]);
```

#### 全连接层
$Y = \text{activation}(W \cdot X + b)$

### 16.5 CUDA 卷积内核

```cpp
__global__ void conv_forward(float *X, float *W, float *Y,
                             int C, int H, int W_in, int K, int M) {
    int m = blockIdx.x;
    int h = blockIdx.y * TILE_WIDTH + threadIdx.y;
    int w = blockIdx.z * TILE_WIDTH + threadIdx.x;
    
    float sum = 0;
    for (int c = 0; c < C; c++)
    for (int p = 0; p < K; p++)
    for (int q = 0; q < K; q++) {
        sum += X[c][h+p][w+q] * W[m][c][p][q];
    }
    Y[m][h][w] = sum;
}
```

### 16.6 GEMM 实现卷积

将卷积转换为矩阵乘法：

1. **展开输入**：将每个输出位置对应的输入 patch 展开为列
2. **滤波器矩阵**：每行是一个 3D 滤波器的展开
3. **矩阵乘法**：$Y = W \cdot X_{unroll}$

```cpp
// 展开内核
__global__ void unroll(float *X, float *X_unroll, int C, int H, int W, int K) {
    int c = blockIdx.x;
    int h_out = blockIdx.y * blockDim.y + threadIdx.y;
    int w_out = blockIdx.z * blockDim.z + threadIdx.x;
    
    int col = h_out * W_out + w_out;
    for (int p = 0; p < K; p++)
    for (int q = 0; q < K; q++) {
        int row = c * K * K + p * K + q;
        X_unroll[row][col] = X[c][h_out + p][w_out + q];
    }
}
```

**扩展比率**：约 $K^2$ 倍（滤波器大小）

### 16.7 cuDNN

NVIDIA 深度学习库，提供高度优化的：
- 卷积（GEMM、Winograd、FFT）
- 池化
- 激活函数
- 批归一化

## 关键要点

| 层类型 | 计算特点 | 优化方法 |
|-------|---------|---------|
| 卷积 | 计算密集，高并行 | GEMM、Tiling |
| 池化 | 内存密集 | 合并访问 |
| 全连接 | 矩阵乘法 | cuBLAS |

### CNN 特点
- **权重共享**：同一滤波器应用于不同位置
- **局部连接**：每个输出只依赖局部输入
- **层次特征**：低层检测边缘，高层检测复杂模式

### GPU 加速优势
- 高并行度（N × M × H × W）
- 高计算密度
- 矩阵乘法高度优化
